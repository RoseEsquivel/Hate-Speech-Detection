{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "pd.options.display.max_colwidth = 500\n",
    "\n",
    "\n",
    "def read_file(file_name):\n",
    "    df=[]\n",
    "    with open(file_name, 'rb') as f:\n",
    "        df = pickle.load(f)\n",
    "    return df\n",
    "\n",
    "def format_feature_names(x):\n",
    "    ll=[]\n",
    "    param_grid=x['best_params']\n",
    "    for i in x['features']:\n",
    "        #print(i)\n",
    "        if i['name'] == 'ngram':\n",
    "            pg_name=''.join(('features__', i['comb_name'], '__feature_extraction__ngram_range'))\n",
    "            ngram_range=param_grid[pg_name]\n",
    "            reduced='reduced' if i['feature_selection'] == True else ''\n",
    "            ll.append(' '.join((i['name'], ' words', str(tuple(ngram_range)), reduced)))\n",
    "        elif i['name'] == 'type_dependency':\n",
    "            pg_name=''.join(('features__', i['comb_name'], '__feature_extraction__ngram_range'))\n",
    "            ngram_range_td=param_grid[pg_name]\n",
    "            reduced='reduced' if i['feature_selection'] == True else ''\n",
    "            ll.append(' '.join(('ngram typed dependency', str(tuple(ngram_range_td)), reduced)))\n",
    "        elif i['name']=='bert_doc':\n",
    "            reduced=' reduced' if i['feature_selection'] == True else ''\n",
    "            ll.append(''.join(('bert_doc', reduced)))\n",
    "        else:\n",
    "            ll.append(i['name'])\n",
    "    return ' + '.join(ll)\n",
    "\n",
    "def group_results(df, order=True):\n",
    "    df['features_']=[format_feature_names(row) for index, row in df.iterrows()]\n",
    "    \n",
    "    group_df=df[[\n",
    "        'macro avg precision','macro avg recall','macro avg f1-score',\n",
    "        'model_name', 'train_domain', 'test_domain', 'features_']].groupby(\n",
    "        ['train_domain','test_domain','model_name','features_']).agg(\n",
    "        ['mean']\n",
    "    ).round(3)\n",
    "    \n",
    "    if order:\n",
    "        group_df=group_df.sort_values(by=[('macro avg f1-score', 'mean')\n",
    "                      ,('macro avg precision', 'mean')\n",
    "                     ,('macro avg recall', 'mean')], ascending=False)\n",
    "        \n",
    "    group_df.reset_index(inplace=True) \n",
    "\n",
    "    return group_df\n",
    "\n",
    "def get_results_by_model(df, model_name, sort_by, drop_features=True, drop_domains=True):\n",
    "    df=df[\n",
    "    ['train_domain', 'test_domain','features_', 'macro avg precision', 'macro avg recall', 'macro avg f1-score']\n",
    "][df.model_name.isin([model_name])].sort_values(by=[sort_by], ascending=False)\n",
    "    df.reset_index(inplace=True)\n",
    "    \n",
    "    drop_columns=['index']\n",
    "    if drop_features:\n",
    "        drop_columns.append('features_')\n",
    "    \n",
    "    if drop_domains:\n",
    "        drop_columns.append('train_domain')\n",
    "        drop_columns.append('test_domain')\n",
    "        \n",
    "    df=df.drop(drop_columns, axis=1)\n",
    "\n",
    "    df=df.rename(columns={\"macro avg f1-score\": ' - '.join((model_name, 'F1')) })\n",
    "    df=df.rename(columns={\"macro avg precision\": ' - '.join((model_name, 'P'))})\n",
    "    df=df.rename(columns={\"macro avg recall\": ' - '.join((model_name, 'R'))})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 10: Classifications result of the models using individual features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ezgidaldal/anaconda3/envs/t37/lib/python3.7/site-packages/pandas-1.2.1-py3.7-macosx-10.9-x86_64.egg/pandas/core/generic.py:4152: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>train_domain</th>\n",
       "      <th>test_domain</th>\n",
       "      <th>features_</th>\n",
       "      <th>logistic_regression - P</th>\n",
       "      <th>logistic_regression - R</th>\n",
       "      <th>logistic_regression - F1</th>\n",
       "      <th>svm - P</th>\n",
       "      <th>svm - R</th>\n",
       "      <th>svm - F1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BHOCS</td>\n",
       "      <td>BHOCS</td>\n",
       "      <td>sentiment</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.527</td>\n",
       "      <td>0.554</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0.545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BHOCS</td>\n",
       "      <td>BHOCS</td>\n",
       "      <td>ngram typed dependency (1, 4) reduced</td>\n",
       "      <td>0.682</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.689</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BHOCS</td>\n",
       "      <td>BHOCS</td>\n",
       "      <td>ngram typed dependency (1, 4)</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BHOCS</td>\n",
       "      <td>BHOCS</td>\n",
       "      <td>ngram typed dependency (1, 1) reduced</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BHOCS</td>\n",
       "      <td>BHOCS</td>\n",
       "      <td>ngram typed dependency (1, 1)</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BHOCS</td>\n",
       "      <td>BHOCS</td>\n",
       "      <td>ngram  words (1, 4) reduced</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BHOCS</td>\n",
       "      <td>BHOCS</td>\n",
       "      <td>ngram  words (1, 4)</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BHOCS</td>\n",
       "      <td>BHOCS</td>\n",
       "      <td>ngram  words (1, 1) reduced</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BHOCS</td>\n",
       "      <td>BHOCS</td>\n",
       "      <td>ngram  words (1, 1)</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BHOCS</td>\n",
       "      <td>BHOCS</td>\n",
       "      <td>bert_doc reduced</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BHOCS</td>\n",
       "      <td>BHOCS</td>\n",
       "      <td>bert_doc</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.716</td>\n",
       "      <td>0.721</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_domain test_domain                              features_  \\\n",
       "                                                                     \n",
       "0         BHOCS       BHOCS                              sentiment   \n",
       "1         BHOCS       BHOCS  ngram typed dependency (1, 4) reduced   \n",
       "2         BHOCS       BHOCS         ngram typed dependency (1, 4)    \n",
       "3         BHOCS       BHOCS  ngram typed dependency (1, 1) reduced   \n",
       "4         BHOCS       BHOCS         ngram typed dependency (1, 1)    \n",
       "5         BHOCS       BHOCS            ngram  words (1, 4) reduced   \n",
       "6         BHOCS       BHOCS                   ngram  words (1, 4)    \n",
       "7         BHOCS       BHOCS            ngram  words (1, 1) reduced   \n",
       "8         BHOCS       BHOCS                   ngram  words (1, 1)    \n",
       "9         BHOCS       BHOCS                       bert_doc reduced   \n",
       "10        BHOCS       BHOCS                               bert_doc   \n",
       "\n",
       "   logistic_regression - P logistic_regression - R logistic_regression - F1  \\\n",
       "                      mean                    mean                     mean   \n",
       "0                    0.532                   0.531                    0.527   \n",
       "1                    0.682                   0.681                    0.681   \n",
       "2                    0.685                   0.685                    0.684   \n",
       "3                    0.688                   0.686                    0.686   \n",
       "4                    0.688                   0.688                    0.687   \n",
       "5                    0.740                   0.730                    0.728   \n",
       "6                    0.747                   0.737                    0.734   \n",
       "7                    0.737                   0.736                    0.736   \n",
       "8                    0.738                   0.738                    0.737   \n",
       "9                    0.717                   0.717                    0.717   \n",
       "10                   0.717                   0.717                    0.716   \n",
       "\n",
       "   svm - P svm - R svm - F1  \n",
       "      mean    mean     mean  \n",
       "0    0.554   0.551    0.545  \n",
       "1    0.689   0.688    0.687  \n",
       "2    0.688   0.688    0.687  \n",
       "3    0.677   0.675    0.675  \n",
       "4    0.686   0.684    0.683  \n",
       "5    0.746   0.738    0.735  \n",
       "6    0.746   0.741    0.740  \n",
       "7    0.737   0.736    0.736  \n",
       "8    0.745   0.745    0.745  \n",
       "9    0.710   0.709    0.709  \n",
       "10   0.721   0.720    0.720  "
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=read_file('../experiments/2_rq1/results_rq1.pkl')\n",
    "df=df[(df['train_domain'] == 'BHOCS') & \n",
    "      (df['test_domain'] == 'BHOCS') & \n",
    "      df.model_name.isin(['logistic_regression', 'svm', 'cnn'])]\n",
    "df=group_results(df, order=True)\n",
    "\n",
    "df=df[~df['features_'].str.contains('\\+')]\n",
    "\n",
    "lr=get_results_by_model(df, 'logistic_regression', 'features_', drop_features=False, drop_domains=False)\n",
    "svm=get_results_by_model(df, 'svm', 'features_',)\n",
    "pd.concat([lr, svm], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ezgidaldal/anaconda3/envs/t37/lib/python3.7/site-packages/pandas-1.2.1-py3.7-macosx-10.9-x86_64.egg/pandas/core/generic.py:4152: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>train_domain</th>\n",
       "      <th>test_domain</th>\n",
       "      <th>features_</th>\n",
       "      <th>cnn - P</th>\n",
       "      <th>cnn - R</th>\n",
       "      <th>cnn - F1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BHOCS</td>\n",
       "      <td>BHOCS</td>\n",
       "      <td>bert_word</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  train_domain test_domain  features_ cnn - P cnn - R cnn - F1\n",
       "                                         mean    mean     mean\n",
       "0        BHOCS       BHOCS  bert_word   0.741   0.733     0.73"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn=get_results_by_model(df, 'cnn', 'features_', drop_features=False, drop_domains=False)\n",
    "cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 11 - 12 : Classifications result of the models using combined features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ezgidaldal/anaconda3/envs/t37/lib/python3.7/site-packages/pandas-1.2.1-py3.7-macosx-10.9-x86_64.egg/pandas/core/generic.py:4152: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n",
      "/Users/ezgidaldal/anaconda3/envs/t37/lib/python3.7/site-packages/pandas-1.2.1-py3.7-macosx-10.9-x86_64.egg/pandas/core/generic.py:4152: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>train_domain</th>\n",
       "      <th>test_domain</th>\n",
       "      <th>features_</th>\n",
       "      <th>logistic_regression - P</th>\n",
       "      <th>logistic_regression - R</th>\n",
       "      <th>logistic_regression - F1</th>\n",
       "      <th>svm - P</th>\n",
       "      <th>svm - R</th>\n",
       "      <th>svm - F1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BHOCS</td>\n",
       "      <td>BHOCS</td>\n",
       "      <td>sentiment + ngram  words (1, 1) reduced</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.743</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BHOCS</td>\n",
       "      <td>BHOCS</td>\n",
       "      <td>sentiment + ngram  words (1, 1)</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BHOCS</td>\n",
       "      <td>BHOCS</td>\n",
       "      <td>ngram  words (1, 1)  + ngram typed dependency (1, 4) reduced</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BHOCS</td>\n",
       "      <td>BHOCS</td>\n",
       "      <td>ngram  words (1, 1)  + ngram typed dependency (1, 4)</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BHOCS</td>\n",
       "      <td>BHOCS</td>\n",
       "      <td>ngram  words (1, 1)  + ngram typed dependency (1, 1) reduced</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BHOCS</td>\n",
       "      <td>BHOCS</td>\n",
       "      <td>ngram  words (1, 1)  + ngram typed dependency (1, 1)</td>\n",
       "      <td>0.743</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BHOCS</td>\n",
       "      <td>BHOCS</td>\n",
       "      <td>ngram  words (1, 1)  + bert_doc reduced</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BHOCS</td>\n",
       "      <td>BHOCS</td>\n",
       "      <td>ngram  words (1, 1)  + bert_doc</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BHOCS</td>\n",
       "      <td>BHOCS</td>\n",
       "      <td>sentiment + ngram  words (1, 4) reduced</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.724</td>\n",
       "      <td>0.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BHOCS</td>\n",
       "      <td>BHOCS</td>\n",
       "      <td>sentiment + ngram  words (1, 4)</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BHOCS</td>\n",
       "      <td>BHOCS</td>\n",
       "      <td>ngram typed dependency (1, 1) reduced + ngram  words (1, 4) reduced</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BHOCS</td>\n",
       "      <td>BHOCS</td>\n",
       "      <td>ngram typed dependency (1, 1) reduced + ngram  words (1, 4)</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BHOCS</td>\n",
       "      <td>BHOCS</td>\n",
       "      <td>ngram typed dependency (1, 1)  + ngram  words (1, 4) reduced</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BHOCS</td>\n",
       "      <td>BHOCS</td>\n",
       "      <td>ngram typed dependency (1, 1)  + ngram  words (1, 4)</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BHOCS</td>\n",
       "      <td>BHOCS</td>\n",
       "      <td>ngram  words (1, 4)  + ngram typed dependency (1, 4) reduced</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BHOCS</td>\n",
       "      <td>BHOCS</td>\n",
       "      <td>ngram  words (1, 4)  + ngram typed dependency (1, 4)</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BHOCS</td>\n",
       "      <td>BHOCS</td>\n",
       "      <td>ngram  words (1, 4)  + bert_doc reduced</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BHOCS</td>\n",
       "      <td>BHOCS</td>\n",
       "      <td>ngram  words (1, 4)  + bert_doc</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  train_domain test_domain  \\\n",
       "                             \n",
       "0        BHOCS       BHOCS   \n",
       "1        BHOCS       BHOCS   \n",
       "2        BHOCS       BHOCS   \n",
       "3        BHOCS       BHOCS   \n",
       "4        BHOCS       BHOCS   \n",
       "5        BHOCS       BHOCS   \n",
       "6        BHOCS       BHOCS   \n",
       "7        BHOCS       BHOCS   \n",
       "0        BHOCS       BHOCS   \n",
       "1        BHOCS       BHOCS   \n",
       "2        BHOCS       BHOCS   \n",
       "3        BHOCS       BHOCS   \n",
       "4        BHOCS       BHOCS   \n",
       "5        BHOCS       BHOCS   \n",
       "6        BHOCS       BHOCS   \n",
       "7        BHOCS       BHOCS   \n",
       "8        BHOCS       BHOCS   \n",
       "9        BHOCS       BHOCS   \n",
       "\n",
       "                                                             features_  \\\n",
       "                                                                         \n",
       "0                              sentiment + ngram  words (1, 1) reduced   \n",
       "1                                     sentiment + ngram  words (1, 1)    \n",
       "2         ngram  words (1, 1)  + ngram typed dependency (1, 4) reduced   \n",
       "3                ngram  words (1, 1)  + ngram typed dependency (1, 4)    \n",
       "4         ngram  words (1, 1)  + ngram typed dependency (1, 1) reduced   \n",
       "5                ngram  words (1, 1)  + ngram typed dependency (1, 1)    \n",
       "6                              ngram  words (1, 1)  + bert_doc reduced   \n",
       "7                                      ngram  words (1, 1)  + bert_doc   \n",
       "0                              sentiment + ngram  words (1, 4) reduced   \n",
       "1                                     sentiment + ngram  words (1, 4)    \n",
       "2  ngram typed dependency (1, 1) reduced + ngram  words (1, 4) reduced   \n",
       "3         ngram typed dependency (1, 1) reduced + ngram  words (1, 4)    \n",
       "4         ngram typed dependency (1, 1)  + ngram  words (1, 4) reduced   \n",
       "5                ngram typed dependency (1, 1)  + ngram  words (1, 4)    \n",
       "6         ngram  words (1, 4)  + ngram typed dependency (1, 4) reduced   \n",
       "7                ngram  words (1, 4)  + ngram typed dependency (1, 4)    \n",
       "8                              ngram  words (1, 4)  + bert_doc reduced   \n",
       "9                                      ngram  words (1, 4)  + bert_doc   \n",
       "\n",
       "  logistic_regression - P logistic_regression - R logistic_regression - F1  \\\n",
       "                     mean                    mean                     mean   \n",
       "0                   0.735                   0.735                    0.735   \n",
       "1                   0.736                   0.736                    0.735   \n",
       "2                   0.750                   0.749                    0.749   \n",
       "3                   0.747                   0.746                    0.746   \n",
       "4                   0.750                   0.749                    0.749   \n",
       "5                   0.743                   0.742                    0.742   \n",
       "6                   0.757                   0.757                    0.757   \n",
       "7                   0.758                   0.757                    0.757   \n",
       "0                   0.752                   0.738                    0.734   \n",
       "1                   0.747                   0.730                    0.725   \n",
       "2                   0.742                   0.739                    0.738   \n",
       "3                   0.748                   0.742                    0.740   \n",
       "4                   0.749                   0.741                    0.739   \n",
       "5                   0.747                   0.739                    0.737   \n",
       "6                   0.747                   0.738                    0.736   \n",
       "7                   0.746                   0.738                    0.735   \n",
       "8                   0.768                   0.766                    0.766   \n",
       "9                   0.761                   0.760                    0.760   \n",
       "\n",
       "  svm - P svm - R svm - F1  \n",
       "     mean    mean     mean  \n",
       "0   0.743   0.742    0.742  \n",
       "1   0.740   0.739    0.739  \n",
       "2   0.753   0.752    0.752  \n",
       "3   0.746   0.746    0.746  \n",
       "4   0.749   0.749    0.749  \n",
       "5   0.748   0.748    0.747  \n",
       "6   0.745   0.744    0.744  \n",
       "7   0.750   0.749    0.749  \n",
       "0   0.732   0.724    0.722  \n",
       "1   0.739   0.727    0.724  \n",
       "2   0.737   0.727    0.724  \n",
       "3   0.745   0.744    0.744  \n",
       "4   0.741   0.735    0.734  \n",
       "5   0.739   0.739    0.739  \n",
       "6   0.744   0.732    0.729  \n",
       "7   0.749   0.748    0.748  \n",
       "8   0.756   0.755    0.754  \n",
       "9   0.760   0.758    0.758  "
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=read_file('../experiments/1_rq1/results_rq1.pkl')\n",
    "df=df[(df['train_domain'] == 'BHOCS') & \n",
    "      (df['test_domain'] == 'BHOCS') & \n",
    "      df.model_name.isin(['logistic_regression', 'svm', 'cnn'])]\n",
    "df=group_results(df, order=True)\n",
    "\n",
    "df=df[df['features_'].str.count('\\+') <= 1]\n",
    "df=df[(df['features_'].str.contains('ngram  words \\(1, 1\\)  \\+')) |\n",
    "      (df['features_'].str.contains('\\+ ngram  words \\(1, 1\\)'))\n",
    "     ]\n",
    "\n",
    "lr=get_results_by_model(df, 'logistic_regression', 'features_', drop_features=False, drop_domains=False)\n",
    "svm=get_results_by_model(df, 'svm', 'features_',)\n",
    "ngram_11=pd.concat([lr, svm], axis=1)\n",
    "\n",
    "#\n",
    "df=read_file('../experiments/1_rq1/results_rq1.pkl')\n",
    "df=df[(df['train_domain'] == 'BHOCS') & \n",
    "      (df['test_domain'] == 'BHOCS') & \n",
    "      df.model_name.isin(['logistic_regression', 'svm', 'cnn'])]\n",
    "df=group_results(df, order=True)\n",
    "\n",
    "df=df[df['features_'].str.count('\\+') <= 1]\n",
    "df=df[(df['features_'].str.contains('ngram  words \\(1, 4\\)  \\+')) |\n",
    "      (df['features_'].str.contains('\\+ ngram  words \\(1, 4\\)'))\n",
    "     ]\n",
    "\n",
    "lr=get_results_by_model(df, 'logistic_regression', 'features_', drop_features=False, drop_domains=False)\n",
    "svm=get_results_by_model(df, 'svm', 'features_',)\n",
    "ngram_14=pd.concat([lr, svm], axis=1)\n",
    "\n",
    "pd.concat([ngram_11, ngram_14], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 13: The comparison of the results obtained from Logit, SVM, and CNN with the baselines. The models trained and tested on the bhosc data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>train_domain</th>\n",
       "      <th>test_domain</th>\n",
       "      <th>model_name</th>\n",
       "      <th>features_</th>\n",
       "      <th>macro avg precision</th>\n",
       "      <th>macro avg recall</th>\n",
       "      <th>macro avg f1-score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BHOCS</td>\n",
       "      <td>BHOCS</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>ngram  words (1, 4)  + ngram typed dependency (1, 4) reduced + bert_doc reduced</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BHOCS</td>\n",
       "      <td>BHOCS</td>\n",
       "      <td>svm</td>\n",
       "      <td>ngram  words (1, 4)  + ngram typed dependency (1, 4)  + bert_doc reduced</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>BHOCS</td>\n",
       "      <td>BHOCS</td>\n",
       "      <td>cnn</td>\n",
       "      <td>bert_word</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>BHOCS</td>\n",
       "      <td>BHOCS</td>\n",
       "      <td>gender_word</td>\n",
       "      <td>gender_word</td>\n",
       "      <td>0.729</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>BHOCS</td>\n",
       "      <td>BHOCS</td>\n",
       "      <td>threshold_classifier</td>\n",
       "      <td>threshold_classifier</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_domain test_domain            model_name  \\\n",
       "                                                     \n",
       "0          BHOCS       BHOCS   logistic_regression   \n",
       "1          BHOCS       BHOCS                   svm   \n",
       "258        BHOCS       BHOCS                   cnn   \n",
       "297        BHOCS       BHOCS           gender_word   \n",
       "298        BHOCS       BHOCS  threshold_classifier   \n",
       "\n",
       "                                                                           features_  \\\n",
       "                                                                                       \n",
       "0    ngram  words (1, 4)  + ngram typed dependency (1, 4) reduced + bert_doc reduced   \n",
       "1           ngram  words (1, 4)  + ngram typed dependency (1, 4)  + bert_doc reduced   \n",
       "258                                                                        bert_word   \n",
       "297                                                                      gender_word   \n",
       "298                                                             threshold_classifier   \n",
       "\n",
       "    macro avg precision macro avg recall macro avg f1-score  \n",
       "                   mean             mean               mean  \n",
       "0                 0.774            0.772              0.771  \n",
       "1                 0.774            0.772              0.771  \n",
       "258               0.741            0.733              0.730  \n",
       "297               0.729            0.649              0.616  \n",
       "298               0.604            0.604              0.604  "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=read_file('../experiments/2_rq1/results_rq1.pkl')\n",
    "df=group_results(df, order=True)\n",
    "\n",
    "lr=df[df.model_name.isin(['logistic_regression'])].head(1)\n",
    "svm=df[df.model_name.isin(['svm'])].head(1)\n",
    "df=df[~df.model_name.isin(['svm','logistic_regression'])]\n",
    "pd.concat([df, lr, svm]).sort_values(by=[('macro avg f1-score', 'mean')], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 14: The robustnes of the classifiers when trained on the bhocs data and tested across datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ezgidaldal/anaconda3/envs/t37/lib/python3.7/site-packages/pandas-1.2.1-py3.7-macosx-10.9-x86_64.egg/pandas/core/generic.py:4152: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>train_domain</th>\n",
       "      <th>test_domain</th>\n",
       "      <th>logistic_regression - P</th>\n",
       "      <th>logistic_regression - R</th>\n",
       "      <th>logistic_regression - F1</th>\n",
       "      <th>svm - P</th>\n",
       "      <th>svm - R</th>\n",
       "      <th>svm - F1</th>\n",
       "      <th>cnn - P</th>\n",
       "      <th>cnn - R</th>\n",
       "      <th>cnn - F1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BHOCS</td>\n",
       "      <td>S</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.689</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.664</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BHOCS</td>\n",
       "      <td>CM</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.668</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.668</td>\n",
       "      <td>0.666</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BHOCS</td>\n",
       "      <td>C</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.729</td>\n",
       "      <td>0.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BHOCS</td>\n",
       "      <td>BHOM</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.666</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.639</td>\n",
       "      <td>0.617</td>\n",
       "      <td>0.602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BHOCS</td>\n",
       "      <td>BHOCSM</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.689</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.668</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.634</td>\n",
       "      <td>0.622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BHOCS</td>\n",
       "      <td>BHOCS</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BHOCS</td>\n",
       "      <td>BHO</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  train_domain test_domain logistic_regression - P logistic_regression - R  \\\n",
       "                                              mean                    mean   \n",
       "0        BHOCS           S                   0.692                   0.690   \n",
       "1        BHOCS          CM                   0.694                   0.676   \n",
       "2        BHOCS           C                   0.754                   0.747   \n",
       "3        BHOCS        BHOM                   0.702                   0.679   \n",
       "4        BHOCS      BHOCSM                   0.692                   0.678   \n",
       "5        BHOCS       BHOCS                   0.774                   0.772   \n",
       "6        BHOCS         BHO                   0.839                   0.839   \n",
       "\n",
       "  logistic_regression - F1 svm - P svm - R svm - F1 cnn - P cnn - R cnn - F1  \n",
       "                      mean    mean    mean     mean    mean    mean     mean  \n",
       "0                    0.689   0.700   0.697    0.696   0.664   0.657    0.653  \n",
       "1                    0.668   0.697   0.677    0.668   0.666   0.642    0.628  \n",
       "2                    0.745   0.762   0.755    0.753   0.742   0.729    0.725  \n",
       "3                    0.670   0.686   0.666    0.657   0.639   0.617    0.602  \n",
       "4                    0.672   0.689   0.674    0.668   0.652   0.634    0.622  \n",
       "5                    0.771   0.774   0.772    0.771   0.741   0.733    0.730  \n",
       "6                    0.839   0.827   0.826    0.826   0.782   0.774    0.772  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=read_file('../experiments/3_rq2_across_data_domains/results_rq2.pkl')\n",
    "df=df[(df['train_domain'] == 'BHOCS') & df.model_name.isin(['logistic_regression', 'svm', 'cnn'])]\n",
    "df=group_results(df, order=True)\n",
    "drop_domains\n",
    "lr=get_results_by_model(df, 'logistic_regression', 'test_domain', drop_domains=False)\n",
    "svm=get_results_by_model(df, 'svm', 'test_domain')\n",
    "cnn=get_results_by_model(df, 'cnn', 'test_domain')\n",
    "\n",
    "pd.concat([lr, svm, cnn], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 15: The performance of the classifiers when trained across 6 datasets and tested on the scales dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ezgidaldal/anaconda3/envs/t37/lib/python3.7/site-packages/pandas-1.2.1-py3.7-macosx-10.9-x86_64.egg/pandas/core/generic.py:4152: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>train_domain</th>\n",
       "      <th>test_domain</th>\n",
       "      <th>logistic_regression - P</th>\n",
       "      <th>logistic_regression - R</th>\n",
       "      <th>logistic_regression - F1</th>\n",
       "      <th>svm - P</th>\n",
       "      <th>svm - R</th>\n",
       "      <th>svm - F1</th>\n",
       "      <th>cnn - P</th>\n",
       "      <th>cnn - R</th>\n",
       "      <th>cnn - F1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CM</td>\n",
       "      <td>S</td>\n",
       "      <td>0.571</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.459</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.546</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "      <td>S</td>\n",
       "      <td>0.524</td>\n",
       "      <td>0.516</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.441</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.487</td>\n",
       "      <td>0.427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BHOM</td>\n",
       "      <td>S</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.506</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.507</td>\n",
       "      <td>0.527</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BHOCSM</td>\n",
       "      <td>S</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.666</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.673</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.664</td>\n",
       "      <td>0.662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BHOCS</td>\n",
       "      <td>S</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.689</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.664</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BHO</td>\n",
       "      <td>S</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.539</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.554</td>\n",
       "      <td>0.541</td>\n",
       "      <td>0.502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  train_domain test_domain logistic_regression - P logistic_regression - R  \\\n",
       "                                              mean                    mean   \n",
       "0           CM           S                   0.571                   0.532   \n",
       "1            C           S                   0.524                   0.516   \n",
       "2         BHOM           S                   0.536                   0.530   \n",
       "3       BHOCSM           S                   0.678                   0.670   \n",
       "4        BHOCS           S                   0.692                   0.690   \n",
       "5          BHO           S                   0.551                   0.543   \n",
       "\n",
       "  logistic_regression - F1 svm - P svm - R svm - F1 cnn - P cnn - R cnn - F1  \n",
       "                      mean    mean    mean     mean    mean    mean     mean  \n",
       "0                    0.459   0.572   0.528    0.448   0.546   0.533    0.480  \n",
       "1                    0.455   0.510   0.504    0.441   0.490   0.487    0.427  \n",
       "2                    0.506   0.537   0.533    0.507   0.527   0.520    0.486  \n",
       "3                    0.666   0.684   0.677    0.673   0.667   0.664    0.662  \n",
       "4                    0.689   0.700   0.697    0.696   0.664   0.657    0.653  \n",
       "5                    0.525   0.547   0.539    0.513   0.554   0.541    0.502  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=read_file('../experiments/3_rq2_across_data_domains/results_rq2.pkl')\n",
    "df=df[(df['test_domain'] == 'S') & df.model_name.isin(['logistic_regression', 'svm', 'cnn'])]\n",
    "df=group_results(df, order=True)\n",
    "\n",
    "lr=get_results_by_model(df, 'logistic_regression', 'train_domain', drop_domains=False)\n",
    "svm=get_results_by_model(df, 'svm', 'train_domain')\n",
    "cnn=get_results_by_model(df, 'cnn', 'train_domain')\n",
    "\n",
    "pd.concat([lr, svm, cnn], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:t37]",
   "language": "python",
   "name": "conda-env-t37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
